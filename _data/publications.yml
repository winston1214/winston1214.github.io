- title: "VisEscape: A Benchmark for Evaluating Exploration-driven Decision-making in Virtual Escape Rooms"
  authors: Seungwon Lim, Sungwoong Kim, Jihwan Yu, Sungjae Lee, Jiwan Chung, Youngjae Yu
  url: https://arxiv.org/abs/2503.14427
  journal: Under Review
  image: visescape.png
  summary: <strong>TLDR;</strong> We introduce <strong>VisEscape</strong> inspired by Escape Room games, and evaluate the <strong>Reasoning</strong> and <strong>Decision-making</strong> of diverse MLLMs in exploration-driven and dynamic environments.

- title: "Persona Dynamics: Unveiling the Impact of Persona Traits on Agents in Text-Based Games"
  authors: Seungwon Lim, Seungbeen Lee, Dongjun Min, Youngjae Yu 
  url: https://arxiv.org/abs/2504.06868
  journal: Under Review
  image: panda.png
  summary: <strong>TLDR;</strong> We introduce <strong>PANDA</strong>, which incorporates <strong>Human Personality Traits</strong> into AI agents for <strong>Text-based Games</strong> and examines how these traits impact their behavior and performance.

- title: "Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics"
  authors: Seungwon Lim*, Seungbeen Lee*, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu
  url: https://arxiv.org/abs/2406.14703
  journal: NAACL2025 Findings
  image: trait.png
  summary: <strong>TLDR;</strong> We introduce a psychometric-based benchmark <strong>TRAIT</strong> to measure the personality revealed in the <strong>Behavior Patterns of LLMs</strong> along with verification of <strong>Reliability</strong> and <strong>Validity</strong>.

- title: "MASS: Overcoming Language Bias in Image-Text Matching"
  authors: Jiwan Chung, Seungwon Lim, Sangkyu Lee and Youngjae Yu
  url: https://arxiv.org/abs/2501.11469
  journal: AAAI2025 Main 
  image: mass.png
  summary: <strong>TLDR;</strong> We introduce <strong>MASS</strong>, a <strong>Training-free</strong> framework that improves <strong>Visual Accuracy</strong> and reduces <strong>Bias in Image-Text Matching</strong> for pretrained visual-language models.

- title: "Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"
  authors: Jiwan Chung, Seungwon Lim, Jaehyun Jeon, Seungbeen Lee and Youngjae Yu
  url: https://arxiv.org/abs/2410.01023
  journal: EMNLP2024 Main
  image: visualpun.png
  summary: <strong>TLDR;</strong> We introduce <strong>UNPIE</strong>, a new benchmark crafted to evaluate how multimodal inputs influence the <strong>Resolution of Lexical Ambiguities</strong>.

- title: "CLARA: Classifying and Disambiguating User Commands for Reliable Interactive Robotic Agents"
  authors: Jeongeun Park, Seungwon Lim, Joonhyung Lee, Sangbeom Park, Minsuk Chang, Youngjae Yu and Sungjoon Choi
  url: https://arxiv.org/abs/2306.10376
  journal: ICRA2024
  image: clara.png
  summary: <strong>TLDR;</strong> We introduce <strong>CLARA</strong>, a LLM-empowered method for robots to estimate <strong>Uncertainty</strong> of user commands and to <strong>Disambiguate</strong> them via question generation for clarification.


  
